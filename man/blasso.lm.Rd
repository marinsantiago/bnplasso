% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/blasso.R
\name{blasso.lm}
\alias{blasso.lm}
\title{Fit linear regression models with a Bayesian Lasso prior}
\usage{
blasso.lm(
  X,
  y,
  a,
  b,
  intercept = FALSE,
  variance.prior.type = "conjugate",
  max.iters = 6000L,
  burn.in = 1000L,
  thin = 1L
)
}
\arguments{
\item{X}{A matrix of predictors of dimension \eqn{n}-by-\eqn{p}, where each 
of the \eqn{n} rows is an observation vector.}

\item{y}{Response variable. It should be a numeric vector size \eqn{n}.}

\item{a}{A positive scalar corresponding to the \bold{shape} parameter in the 
gamma distribution used as hyper-prior in the shrinkage parameter 
\eqn{\lambda^{2}}.}

\item{b}{A positive scalar corresponding to the \bold{rate} parameter in the 
gamma distribution used as hyper-prior in the shrinkage parameter 
\eqn{\lambda^{2}}.}

\item{intercept}{Logical. If \code{TRUE} an intercept term is included in the
model; otherwise, the intercept is integrated out. Default is \code{TRUE}.}

\item{variance.prior.type}{A character string denoting whether the variance 
on the sampling variance should be an independent-type prior or a 
conjugate-type prior. See Moran et al. (2019) for details. The options are
 either \code{"independent"} or \code{"conjugate"}. 
 Default is \code{"conjugate"} as in Park and Casella (2008).}

\item{max.iters}{A positive integer corresponding to the total number of 
MCMC iterations. Default is 6000.}

\item{burn.in}{A positive integer corresponding to the number of draws 
discarded as burn-in. It should be smaller than \code{max.iters}.
Default is 1000.}

\item{thin}{A positive integer specifying the period for saving samples.
Default is 1.}
}
\value{
An object of S3 class, "lmBayes", containing:
\itemize{
  \item \code{Post.beta}: A matrix of size \code{n.draws}-by-\code{n.preds}, 
  where each row is a posterior draw of the regression coefficients.
  \item \code{Post.sigma2}: A vector of size \code{n.draws}, where each 
  element is a posterior draw of the sampling variance. 
  \item \code{Post.tau2}: A matrix of size \code{n.draws}-by-\code{n.preds}, 
  where each row is a posterior draw of the latent parameters 
  \eqn{\tau_{j}^{2}}.
  \item \code{Post.lambda2}: A matrix of size 
  \code{n.draws}-by-\code{n.preds}, where each row is a posterior draw of the
  shrinkage parameters \eqn{\lambda_{j}^{2}}.
  \item \code{Post.mu}: A vector of size \code{n.draws}, where each element 
  is a posterior draw of the intercept term.
  \item \code{elapsed}: The elapsed (wall-clock) time of the MCMC sampler.
  \item \code{a}: The \bold{shape} parameter in the gamma distribution 
  used as a hyper-prior.
  \item \code{b}: The \bold{rate} parameter in the gamma distribution 
  used as a hyper-prior.  
  \item \code{intercept}: Whether or not an intercept term was included in 
  the model.
  \item \code{variance.prior.type}: Whether the variance on the sampling 
  variance was an independent-type prior or a conjugate-type prior.
  \item \code{max.iters}: The total number of MCMC iterations.
  \item \code{burn.in}: The number of draws discarded as burn-in.
  \item \code{thin}: The period for saving draws.
  \item \code{n.obs}: The sample size.   
  \item \code{n.preds}: The number of predictors.
  \item \code{n.draws}: The number of posterior draws after burn-in and
  thinning.
  \item \code{X}: Matrix of predictors.
  \item \code{y}: Vector of responses.
  \item \code{post.pred.fitted.values}: A matrix of size 
  \code{n.draws}-by-\code{n.obs}, where each row is a draw from the posterior 
  predictive distribution of the fitted values.
  \item \code{post.pred.residuals}: A matrix of size 
  \code{n.draws}-by-\code{n.obs}, where each row is a draw from the posterior 
  predictive distribution of the residuals.  
}
}
\description{
This function fits linear regression models with a Bayesian Lasso prior as in
Park and Casella (2008).
}
\references{
G. E. Moran, V. Rockova, and E. I. George (2019), Variance Prior Forms for 
High-Dimensional Bayesian Variable Selection. \emph{Bayesian Analysis},
14(4):1091-1119.

T. Park, and G. Casella (2008), The Bayesian Lasso. 
\emph{Journal of the American Statistical Association}, 103(482):681-686.
}
\author{
Santiago Marin
}
